{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\junka\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the file and dropped some less useful columns.\n",
    "\n",
    "side note: for the dates, I just assumed that 'Stay Date' is more important rather than 'Created Date' or 'Published Date'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"tripadvisor_20250213222526.csv\")\n",
    "df = df.drop(columns=['Review Id', 'Display Name', 'User Name', 'User Profile',\n",
    "                      'User Avatar', 'User Is Verified','Additional Ratings', 'Photos',\n",
    "                       'Location Id', 'URL', 'Created Date', 'Published Date', 'Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['User ID', 'User Location', 'Rating', 'Review Title', 'Review Text',\n",
      "       'Helpful Votes', 'Stay Date', 'Language'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed that there are reviews not in english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en' 'zhCN' 'es' 'ru' 'pl' 'fr' 'sv' 'ja' 'ko' 'da' 'in' 'it' 'nl' 'th'\n",
      " 'de' 'ar' 'pt' 'el' 'zhTW' 'tr' 'no' 'vi' 'fi' 'iw' 'sk' 'hu' 'sr' 'cs']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Language\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing non-english reviews, there are 7076 rows left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['User ID', 'User Location', 'Rating', 'Review Title', 'Review Text',\n",
      "       'Helpful Votes', 'Stay Date'],\n",
      "      dtype='object')\n",
      "7076\n"
     ]
    }
   ],
   "source": [
    "df = df[df['Language'] == 'en']\n",
    "#drop Language col after filtering for only english reviews\n",
    "df = df.drop(columns = ['Language'])\n",
    "\n",
    "\n",
    "print(df.columns)  #Displayes the columns in the df\n",
    "print(df.shape[0])  # Displays the number of rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 Locations 'Universal Studios Singapore' and 'Universal Studios Singapore Tickets' but after looking at the reviews, \n",
    "they seem to be used interchangebly by reviewers.\n",
    "\n",
    "I.e. There are reviewers who put the location as 'Universal Studios Singapore Tickets' that also talking about the park as a whole as opposed to just talking about the ticketing system or just the queue.\n",
    "\n",
    "Therefore, will drop 'Location' column as well. (Do it above with the rest to be neater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n\\nprint(df[\"Location\"].unique())\\ncount = df[df[\\'Location\\'] == \\'Universal Studios Singapore Tickets\\'].shape[0]\\nprint(count)\\ncount2 = df[df[\\'Location\\'] == \\'Universal Studios Singapore\\'].shape[0]\\nprint(count2)\\n\\npd.set_option(\\'display.max_colwidth\\', None)  # Set to None to show full text without truncation\\n\\nfiltered_reviews = df[df[\\'Location\\'] == \\'Universal Studios Singapore Tickets\\'][\\'Review Title\\']\\nprint(filtered_reviews)\\n\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "\n",
    "print(df[\"Location\"].unique())\n",
    "count = df[df['Location'] == 'Universal Studios Singapore Tickets'].shape[0]\n",
    "print(count)\n",
    "count2 = df[df['Location'] == 'Universal Studios Singapore'].shape[0]\n",
    "print(count2)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None to show full text without truncation\n",
    "\n",
    "filtered_reviews = df[df['Location'] == 'Universal Studios Singapore Tickets']['Review Title']\n",
    "print(filtered_reviews)\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column 'User Location' has 1654 missing values, we might want to consider removing these too, especially if we're not doing a demographic by location analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID             0\n",
      "User Location    1654\n",
      "Rating              0\n",
      "Review Title        0\n",
      "Review Text         0\n",
      "Helpful Votes       0\n",
      "Stay Date           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())  # Check for missing values in each column\n",
    "# Print the data types of each column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to the right data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID          object\n",
      "User Location    object\n",
      "Rating            int64\n",
      "Review Title     object\n",
      "Review Text      object\n",
      "Helpful Votes     int64\n",
      "Stay Date        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n",
    "\n",
    "#Convert 'Stay Date' to a date type variable\n",
    "df['Stay Date'] = pd.to_datetime(df['Stay Date'], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text preprocessing:\n",
    "\n",
    "Remove special characters, numbers, and extra spaces.\n",
    "\n",
    "Convert text to lowercase.\n",
    "\n",
    "Tokenization (split text into words).\n",
    "\n",
    "Remove stop words (common words like \"the\", \"is\", \"and\", etc. that don’t add much meaning).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Lowercase, remove special characters, and extra spaces.\"\"\"\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text) # Keep only alphanumeric characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra spaces\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words] # Remove stopwords + Lemmatization\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['Clean Review Title'] = df['Review Title'].apply(clean_text)\n",
    "df['Clean Review Text'] = df['Review Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can preview the dataset below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            User ID  User Location  Rating  \\\n",
      "0  2165A55827C624A5FA8BA42A63DA343C  United States       3   \n",
      "1  87364D4E6E971222E18CB6C485C9209E            NaN       5   \n",
      "2  DC02DAA61A0CD9DC77B4C83FC2A79A09      Edinburgh       4   \n",
      "3  3E7A5D8CEA2FB93CCB415499204B9E77            NaN       1   \n",
      "4  C9CC6FD8B4C7A6EC72E0088AF811CA82         Sydney       4   \n",
      "\n",
      "                    Review Title  \\\n",
      "0                      It’s okay   \n",
      "1  Great Staff, Great Experience   \n",
      "2    Great day out, pretty small   \n",
      "3                      Pointless   \n",
      "4                        Fun day   \n",
      "\n",
      "                                         Review Text  Helpful Votes  \\\n",
      "0  This was relatively small, ~24 rides(?), lines...              0   \n",
      "1  Staff at Universal and RWS were so lovely and ...              0   \n",
      "2  Great day out, with plenty of shade and seats ...              0   \n",
      "3  Pointless place.\\nWait times are over 60 mins ...              0   \n",
      "4  Not as good as Universal in LA. \\n\\nHighly rec...              2   \n",
      "\n",
      "   Stay Date            Clean Review Title  \\\n",
      "0 2025-02-28                          okay   \n",
      "1 2025-02-28  great staff great experience   \n",
      "2 2024-03-31        great day pretty small   \n",
      "3 2025-01-31                     pointless   \n",
      "4 2025-01-31                       fun day   \n",
      "\n",
      "                                   Clean Review Text  \n",
      "0  relatively small 24 ride line super long expec...  \n",
      "1  staff universal rws lovely helpful lynn pus bo...  \n",
      "2  great day plenty shade seat get hot also plent...  \n",
      "3  pointless place wait time 60 min ride difficul...  \n",
      "4  good universal la highly recommend spending ex...  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
